# -*- coding: utf-8 -*-
"""Tugas LSTM Time Series.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17ZT-esyMnr6wWKEr-LY7chkezYpkJDN7

# Biodata

**Fida Mardliyah // fidamardliyah11@gmail.com**

Sumber Data : https://www.kaggle.com/bulentsiyah/for-simple-exercises-time-series-forecasting?select=energydata_complete.csv

# Import Data
"""

import pandas as pd
import numpy as np

datats = pd.read_csv('energydata_complete.csv', index_col=0, parse_dates=True, squeeze=True)

datats.head()

datats.info()

datats.shape

"""# Preprocessing

## Missing Value
"""

datats.isnull().sum()

datats.Appliances = datats.Appliances.astype(float)
datats.lights = datats.lights.astype(float)

datats.info()

"""# Plot Awal"""

import matplotlib.pyplot as plt
import seaborn as sns

sns.set(rc={'figure.figsize':(30,15)})

datats['Appliances'].plot(linewidth=1.5);

"""# Split Data"""

energy  = datats['Appliances'].values

from sklearn.model_selection import train_test_split
x_train, x_val, = train_test_split(energy, test_size=0.2, shuffle=False)

print('Jumlah Train: ', len(x_train))
print('Jumlah Validasi: ', len(x_val))

"""# Modelling

## Batch
"""

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
    series = tf.expand_dims(series, axis=-1)
    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(window_size + 1))
    ds = ds.shuffle(shuffle_buffer)
    ds = ds.map(lambda w: (w[:-1], w[-1:]))
    return ds.batch(batch_size).prefetch(1)

"""## LSTM & Sequential"""

import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import Bidirectional
from tensorflow.keras.layers import Dropout

train_set = windowed_dataset(x_train, window_size=60, batch_size=100, shuffle_buffer=1000)
val_set = windowed_dataset(x_val, window_size=60, batch_size=100, shuffle_buffer=1000)
model = Sequential([
  Bidirectional(LSTM(60, return_sequences=True)),
  Bidirectional(LSTM(60)),
  Dropout(0.5),
  Dense(30, activation="relu"),
  Dense(10, activation="relu"),
  Dense(1),
])

"""## Rumus MAE"""

Mae = abs((datats['Appliances'].max() - datats['Appliances'].min()) * 10/100)
print(Mae)

"""## Callbacks"""

class mycb(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('mae')<107.0 and logs.get('val_mae')<107.0):
      print('\nMAE has reach < 10% from data scale'),
      self.model.stop_training = True

"""## Compile Optimizer"""

optimizer = tf.keras.optimizers.SGD(lr=1.0000e-04, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mae"])

"""# Fit Training"""

fitmodel = model.fit(train_set, steps_per_epoch = 25, epochs = 100, 
                     validation_data = val_set, validation_steps=5,
                    callbacks = [mycb()]
                     )

"""# Perbandingan Plot

dikarenakan pada Epoch 1 nilai MAE < 10% dari skala data maka tidak dapat membuat plot perbandingan akurasi dan loss.
"""